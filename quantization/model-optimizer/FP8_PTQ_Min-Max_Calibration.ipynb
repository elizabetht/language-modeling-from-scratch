{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfac263",
   "metadata": {},
   "source": [
    "# FP8 Post-Training Quantization (PTQ) with NVIDIA Model Optimizer\n",
    "\n",
    "This notebook demonstrates how to perform FP8 Post-Training Quantization using NVIDIA's ModelOpt library with Min-Max calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f0bc7",
   "metadata": {},
   "source": [
    "## Configure CUDA Environment\n",
    "\n",
    "Set up environment variables for CUDA toolkit paths, including the CUDA architecture version, PTX assembler path, and library paths required for GPU operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44c8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"12.1\"\n",
    "os.environ[\"TRITON_PTXAS_PATH\"] = \"/usr/local/cuda/bin/ptxas\"\n",
    "os.environ[\"PATH\"] = \"/usr/local/cuda/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1262c",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Install PyTorch 2.9.0 with CUDA 13.0 support, along with bitsandbytes and NVIDIA Model Optimizer. **Note:** Restart the kernel after running this cell before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7699a343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.9.0+cu130\n",
      "Uninstalling torch-2.9.0+cu130:\n",
      "  Successfully uninstalled torch-2.9.0+cu130\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu130\n",
      "Collecting torch==2.9.0\n",
      "  Using cached https://download.pytorch.org/whl/cu130/torch-2.9.0%2Bcu130-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torchvision==0.24.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.24.0)\n",
      "Requirement already satisfied: torchaudio==2.9.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.13.0.50 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (9.13.0.50)\n",
      "Requirement already satisfied: nvidia-cublas==13.0.0.19 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.0.19)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.15 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (12.0.0.15)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.3.29 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (12.0.3.29)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.2.49 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (12.6.2.49)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.27.7 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (2.27.7)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.3.24 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.3.24)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.39)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.39)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.0.42 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (1.15.0.42)\n",
      "Requirement already satisfied: triton==3.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.5.0)\n",
      "Requirement already satisfied: numpy in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torchvision==0.24.0) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torchvision==0.24.0) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.9.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from jinja2->torch==2.9.0) (2.1.5)\n",
      "Using cached https://download.pytorch.org/whl/cu130/torch-2.9.0%2Bcu130-cp312-cp312-manylinux_2_28_aarch64.whl (512.4 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.9.0+cu130\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nvidia-modelopt in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.40.0)\n",
      "Requirement already satisfied: ninja in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (1.13.0)\n",
      "Requirement already satisfied: numpy in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (2.3.5)\n",
      "Requirement already satisfied: packaging in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (2.12.5)\n",
      "Requirement already satisfied: nvidia-ml-py>=12 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (13.590.44)\n",
      "Requirement already satisfied: rich in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (14.2.0)\n",
      "Requirement already satisfied: scipy in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (4.67.1)\n",
      "Requirement already satisfied: pulp in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (3.3.0)\n",
      "Requirement already satisfied: regex in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (2026.1.15)\n",
      "Requirement already satisfied: safetensors in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (0.7.0)\n",
      "Requirement already satisfied: torch>=2.6 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (2.9.0+cu130)\n",
      "Requirement already satisfied: torchprofile>=0.0.4 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from nvidia-modelopt) (0.0.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pydantic>=2.0->nvidia-modelopt) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pydantic>=2.0->nvidia-modelopt) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pydantic>=2.0->nvidia-modelopt) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pydantic>=2.0->nvidia-modelopt) (0.4.2)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.13.0.50 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (9.13.0.50)\n",
      "Requirement already satisfied: nvidia-cublas==13.0.0.19 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (13.0.0.19)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.15 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (12.0.0.15)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.3.29 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (12.0.3.29)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.2.49 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (12.6.2.49)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.27.7 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (2.27.7)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.3.24 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (3.3.24)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (13.0.39)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (13.0.39)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.0.42 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (1.15.0.42)\n",
      "Requirement already satisfied: triton==3.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.6->nvidia-modelopt) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.6->nvidia-modelopt) (1.3.0)\n",
      "Requirement already satisfied: torchvision>=0.4 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torchprofile>=0.0.4->nvidia-modelopt) (0.24.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torchvision>=0.4->torchprofile>=0.0.4->nvidia-modelopt) (12.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.6->nvidia-modelopt) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from rich->nvidia-modelopt) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from rich->nvidia-modelopt) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->nvidia-modelopt) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: huggingface_hub in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: requests in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->huggingface_hub) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->huggingface_hub) (2026.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (4.57.5)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: requests in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers) (2026.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from accelerate) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from accelerate) (7.2.1)\n",
      "Requirement already satisfied: pyyaml in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from accelerate) (2.9.0+cu130)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.10.0)\n",
      "Requirement already satisfied: requests in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.13.0.50 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.13.0.50)\n",
      "Requirement already satisfied: nvidia-cublas==13.0.0.19 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (13.0.0.19)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.15 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.0.0.15)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.3.29 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.0.3.29)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.2.49 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.2.49)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.27.7 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.7)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.3.24 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3.24)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (13.0.39)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (13.0.39)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.0.42 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.15.0.42)\n",
      "Requirement already satisfied: triton==3.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2026.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.12.1)\n",
      "Requirement already satisfied: certifi in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell first, then restart the kernel before running the next cell\n",
    "%pip uninstall torch -y\n",
    "%pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 --index-url https://download.pytorch.org/whl/cu130\n",
    "\n",
    "%pip install bitsandbytes>=0.43.2\n",
    "%pip install nvidia-modelopt\n",
    "%pip install huggingface_hub\n",
    "%pip install transformers\n",
    "%pip install python-dotenv\n",
    "%pip install accelerate\n",
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422ffbd",
   "metadata": {},
   "source": [
    "## Import Libraries, Verify Setup, and Authenticate\n",
    "\n",
    "Import required libraries including PyTorch, transformers, and bitsandbytes. Verify that PyTorch and CUDA are properly installed. Load environment variables from `.env` file and authenticate with HuggingFace Hub to access gated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21395453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu130\n",
      "CUDA available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell after restarting the kernel\n",
    "import os\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# Load environment variables from .env file and login to Hugging Face\n",
    "load_dotenv()\n",
    "login(token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8100f85",
   "metadata": {},
   "source": [
    "## Configure Model and Dataset Parameters\n",
    "\n",
    "Define the model name (Llama-3.1-8B-Instruct), calibration dataset (CNN DailyMail), batch size, and number of calibration samples for quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2a2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "dataset_name = \"cnn_dailymail\"\n",
    "batch_size = 8\n",
    "calib_samples = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449cd784",
   "metadata": {},
   "source": [
    "## Load the Pre-trained Model and Compute Original Size\n",
    "\n",
    "Load the Llama-3.1-8B-Instruct model in bfloat16 precision using automatic device mapping. Load the tokenizer and set the pad token. Import and use the helper function to compute and display the original model size in GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdcd9e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e55d95df8684d30a82e4494731b85b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model size is 16.060522752 GB\n"
     ]
    }
   ],
   "source": [
    "# Load model - use device_map=\"auto\" to handle device placement automatically\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    dtype=torch.bfloat16,  # Must be torch_dtype, not dtype\n",
    "    device_map=\"auto\",           # Don't use .cuda(), use this instead\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")  # Add parent directory to path\n",
    "\n",
    "# Force reload the module to pick up changes\n",
    "import importlib\n",
    "import quantization_theory_helper\n",
    "importlib.reload(quantization_theory_helper)\n",
    "\n",
    "from quantization_theory_helper import compute_module_sizes\n",
    "module_size = compute_module_sizes(model)\n",
    "print(f\"The model size is {module_size[''] * 1e-9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b11c2e",
   "metadata": {},
   "source": [
    "## Import ModelOpt and Prepare Calibration Dataset\n",
    "\n",
    "Import NVIDIA ModelOpt quantization tools and dataset utilities. Create a DataLoader from the CNN DailyMail dataset for calibration, which will be used to collect activation statistics during the quantization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc6da7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/modelopt/torch/utils/dataset_utils.py:198: UserWarning: Tokenizer with the right padding_side may impact calibration accuracy. Recommend set to left\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import modelopt.torch.quantization as mtq\n",
    "from modelopt.torch.utils.dataset_utils import create_forward_loop, get_dataset_dataloader\n",
    "\n",
    "dataloader = get_dataset_dataloader(\n",
    "    dataset_name=dataset_name,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=batch_size,\n",
    "    num_samples=calib_samples,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509ef122",
   "metadata": {},
   "source": [
    "## Create Forward Loop for Calibration\n",
    "\n",
    "Create a forward loop function that will run the calibration data through the model to collect activation statistics for quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3a3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_loop = create_forward_loop(dataloader=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94abdc",
   "metadata": {},
   "source": [
    "## Apply FP8 Quantization\n",
    "\n",
    "Apply FP8 Post-Training Quantization to the model using ModelOpt with Min-Max calibration. This converts the model weights to 8-bit floating point format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e7b41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered <class 'transformers.models.llama.modeling_llama.LlamaAttention'> to _QuantAttention for KV Cache quantization\n",
      "Inserted 771 quantizers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:34<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# Try FP8 instead of FP4 - may have better Blackwell support\n",
    "# If FP8 also fails, Triton doesn't support Blackwell GPUs yet for ModelOpt\n",
    "quant_config = mtq.FP8_DEFAULT_CFG  # Changed from NVFP4_DEFAULT_CFG\n",
    "model = mtq.quantize(model, quant_config, forward_loop=forward_loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bd82d",
   "metadata": {},
   "source": [
    "## Test the Quantized Model\n",
    "\n",
    "Generate text using the quantized model to verify it works correctly. Using eager mode (no torch.compile) for GPU compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce8cd037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading extension modelopt_cuda_ext_fp8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/modelopt/torch/utils/cpp_extension.py:88: UserWarning: Error building extension 'modelopt_cuda_ext_fp8': [1/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output tensor_quant_gpu_fp8.cuda.o.d -DTORCH_EXTENSION_NAME=modelopt_cuda_ext_fp8 -DTORCH_API_INCLUDE_EXTENSION_H -isystem /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/include -isystem /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -isystem /usr/include/python3.12 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_121,code=sm_121 --compiler-options '-fPIC' -std=c++17 -c /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/modelopt/torch/quantization/src/tensor_quant_gpu_fp8.cu -o tensor_quant_gpu_fp8.cuda.o \n",
      "\u001b[31mFAILED: [code=1] \u001b[0mtensor_quant_gpu_fp8.cuda.o \n",
      "/usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output tensor_quant_gpu_fp8.cuda.o.d -DTORCH_EXTENSION_NAME=modelopt_cuda_ext_fp8 -DTORCH_API_INCLUDE_EXTENSION_H -isystem /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/include -isystem /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -isystem /usr/include/python3.12 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_121,code=sm_121 --compiler-options '-fPIC' -std=c++17 -c /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/modelopt/torch/quantization/src/tensor_quant_gpu_fp8.cu -o tensor_quant_gpu_fp8.cuda.o \n",
      "In file included from /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/Device.h:4,\n",
      "                 from /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/python.h:8,\n",
      "                 from /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/include/torch/extension.h:9,\n",
      "                 from /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/modelopt/torch/quantization/src/tensor_quant_gpu_fp8.cu:22:\n",
      "/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/python_headers.h:12:10: fatal error: Python.h: No such file or directory\n",
      "   12 | #include <Python.h>\n",
      "      |          ^~~~~~~~~~\n",
      "compilation terminated.\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "CUDA extension for FP8 quantization could not be built and loaded, FP8 simulated quantization will not be available.\n",
      "  warnings.warn(fail_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Amanda and I am a 33 year old mom\n"
     ]
    }
   ],
   "source": [
    "# Using eager mode (no torch.compile) for Blackwell GPU compatibility\n",
    "inputs = tokenizer(\"Hello, my name is\", return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4f0c0",
   "metadata": {},
   "source": [
    "## Export Quantized Model\n",
    "\n",
    "Export the quantized model in HuggingFace checkpoint format and save the tokenizer to the export directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e02a26e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/modelopt/torch/export/unified_export_hf.py:269: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weight_scaling_factor = torch.tensor(weight_quantizer.amax / weight_quantizer.maxbound)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./quantized_model/fp8/tokenizer_config.json',\n",
       " './quantized_model/fp8/special_tokens_map.json',\n",
       " './quantized_model/fp8/chat_template.jinja',\n",
       " './quantized_model/fp8/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelopt.torch.export import export_hf_checkpoint\n",
    "\n",
    "export_path = \"./quantized_model/fp8/\"\n",
    "export_hf_checkpoint(model, export_dir=export_path)\n",
    "tokenizer.save_pretrained(export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8aa21",
   "metadata": {},
   "source": [
    "## Compute Quantized Model Size\n",
    "\n",
    "Reload the helper module and calculate the size of the quantized model to compare with the original model size and verify the memory savings from quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf4514ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model size is 9.08120448 GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # Add parent directory to path\n",
    "\n",
    "# Force reload the module to pick up changes\n",
    "import importlib\n",
    "import quantization_theory_helper\n",
    "importlib.reload(quantization_theory_helper)\n",
    "\n",
    "from quantization_theory_helper import compute_module_sizes\n",
    "module_size = compute_module_sizes(model)\n",
    "print(f\"The model size is {module_size[''] * 1e-9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab1dc4",
   "metadata": {},
   "source": [
    "## Save Model Config and Create Model Card\n",
    "\n",
    "Save the model configuration to the export directory. Create a comprehensive README.md model card with metadata tags, model details, usage instructions, and licensing information for the HuggingFace model repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e99eab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved config\n",
      "✓ Created model card\n",
      "\n",
      "Model saved to ./quantized_model/fp8//\n",
      "Contents: ['special_tokens_map.json', 'README.md', 'model-00002-of-00002.safetensors', 'tokenizer_config.json', 'chat_template.jinja', 'hf_quant_config.json', 'generation_config.json', 'config.json', 'model-00001-of-00002.safetensors', 'model.safetensors.index.json', 'tokenizer.json']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Save model config\n",
    "model.config.save_pretrained(export_path)\n",
    "print(\"✓ Saved config\")\n",
    "\n",
    "# Create a README model card\n",
    "model_card = \"\"\"---\n",
    "license: llama3.1\n",
    "base_model: meta-llama/Llama-3.1-8B-Instruct\n",
    "tags:\n",
    "  - llama\n",
    "  - quantized\n",
    "  - nvidia-modeloptimizer\n",
    "  - fp8\n",
    "library_name: nvidia-modeloptimizer\n",
    "---\n",
    "\n",
    "# Llama-3.1-8B-Instruct Quantized (ModelOpt FP8)\n",
    "\n",
    "This is a quantized version of [meta-llama/Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) using [modelopt](https://github.com/NVIDIA/Model-Optimizer) with FP8 weight quantization.\n",
    "\n",
    "## Model Details\n",
    "\n",
    "- **Base Model:** meta-llama/Llama-3.1-8B-Instruct\n",
    "- **Quantization Method:** modelopt FP8 Post-Training Quantization (PTQ)    \n",
    "- **Weight Precision:** FP8\n",
    "- **Original Size:** ~16 GB (bfloat16)\n",
    "- **Quantized Size:** ~9 GB\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load base model structure\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"tokenlabsdotrun/Llama-3.1-8B-ModelOpt-FP8\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "# Load tokenizer and generate\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tokenlabsdotrun/Llama-3.1-8B-ModelOpt-FP8\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my name is\", return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "```\n",
    "\n",
    "## License\n",
    "\n",
    "This model inherits the [Llama 3.1 Community License](https://llama.meta.com/llama3_1/license/).\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{export_path}/README.md\", \"w\") as f:\n",
    "    f.write(model_card)\n",
    "print(\"✓ Created model card\")\n",
    "\n",
    "print(f\"\\nModel saved to {export_path}/\")\n",
    "print(\"Contents:\", os.listdir(export_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35964a3b",
   "metadata": {},
   "source": [
    "## Upload to HuggingFace Hub\n",
    "\n",
    "Create a HuggingFace repository and upload the quantized model, tokenizer, and model card to make it publicly available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6868343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Repository created: tokenlabsdotrun/Llama-3.1-8B-ModelOpt-FP8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3396a3cf521745279d22c59c9484a40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682872d7f5e04a86b7cd4d6e4f71be1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded to https://huggingface.co/tokenlabsdotrun/Llama-3.1-8B-ModelOpt-FP8\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import create_repo, upload_folder\n",
    "\n",
    "# Load write token from .env file\n",
    "hf_write_token = os.getenv(\"HF_WRITE_TOKEN\")\n",
    "\n",
    "# Upload to HuggingFace Hub\n",
    "repo_name = \"tokenlabsdotrun/Llama-3.1-8B-ModelOpt-FP8\"  # Change to your username/repo\n",
    "\n",
    "try:\n",
    "    # Create the repo (set private=True if you want it private)\n",
    "    create_repo(repo_name, exist_ok=True, private=False, token=hf_write_token)\n",
    "    print(f\"✓ Repository created: {repo_name}\")\n",
    "    \n",
    "    # Upload all files\n",
    "    upload_folder(\n",
    "        folder_path=export_path,\n",
    "        repo_id=repo_name,\n",
    "        repo_type=\"model\",\n",
    "        commit_message=\"Upload Llama-3.1-8B quantized with ModelOpt FP8\",\n",
    "        token=hf_write_token\n",
    "    )\n",
    "    print(f\"✓ Uploaded to https://huggingface.co/{repo_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ff4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
