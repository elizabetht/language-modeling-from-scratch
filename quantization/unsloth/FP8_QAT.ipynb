{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705d5a22",
   "metadata": {},
   "source": [
    "# FP8 Quantization-Aware Training (QAT) with Unsloth\n",
    "\n",
    "This notebook demonstrates how to perform FP8 Quantization-Aware Training using the Unsloth library for efficient LLM fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0da6f",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Install PyTorch with CUDA support and all required libraries including Unsloth, transformers, TRL (for training), and torchao/fbgemm for FP8 quantization support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59fb715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu130\n",
      "Requirement already satisfied: torch==2.9.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (2.9.0+cu130)\n",
      "Requirement already satisfied: torchvision==0.24.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.24.0)\n",
      "Requirement already satisfied: torchaudio==2.9.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.13.0.50 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (9.13.0.50)\n",
      "Requirement already satisfied: nvidia-cublas==13.0.0.19 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.0.19)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.15 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (12.0.0.15)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.3.29 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (12.0.3.29)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.2.49 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (12.6.2.49)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.27.7 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (2.27.7)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.3.24 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.3.24)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.39)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.39)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.0.42 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (1.15.0.42)\n",
      "Requirement already satisfied: triton==3.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.5.0)\n",
      "Requirement already satisfied: numpy in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torchvision==0.24.0) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torchvision==0.24.0) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.9.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from jinja2->torch==2.9.0) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bitsandbytes in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.49.1)\n",
      "Requirement already satisfied: accelerate in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: xformers==0.0.33.post1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.0.33.post1)\n",
      "Requirement already satisfied: peft in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.18.1)\n",
      "Requirement already satisfied: trl in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.22.2)\n",
      "Requirement already satisfied: triton in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (25.1.1)\n",
      "Requirement already satisfied: unsloth_zoo in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (2026.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentencepiece in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.2.1)\n",
      "Requirement already satisfied: protobuf in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (6.33.4)\n",
      "Requirement already satisfied: datasets==4.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.1.9)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (0.4.0)\n",
      "Requirement already satisfied: pandas in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (2025.9.0)\n",
      "Requirement already satisfied: packaging in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets==4.3.0) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.34.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.34.0) (1.2.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (3.13.3)\n",
      "Requirement already satisfied: anyio in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets==4.3.0) (4.12.1)\n",
      "Requirement already satisfied: certifi in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets==4.3.0) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets==4.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets==4.3.0) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets==4.3.0) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.3.0) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets==4.3.0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets==4.3.0) (2.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pandas->datasets==4.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pandas->datasets==4.3.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pandas->datasets==4.3.0) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==4.3.0) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: unsloth in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (2026.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers==4.55.4 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (4.55.4)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (2026.1.15)\n",
      "Requirement already satisfied: requests in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers==4.55.4) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers==4.55.4) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers==4.55.4) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers==4.55.4) (2026.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: trl==0.22.2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.22.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2026.1.3-py3-none-any.whl.metadata (66 kB)\n",
      "Collecting unsloth_zoo\n",
      "  Downloading unsloth_zoo-2026.1.3-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting wheel>=0.42.0 (from unsloth)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting packaging (from unsloth)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (30 kB)\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (5.9 kB)\n",
      "Collecting numpy (from unsloth)\n",
      "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm (from unsloth)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting psutil (from unsloth)\n",
      "  Downloading psutil-7.2.1-cp36-abi3-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (22 kB)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-1.0.5-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting protobuf (from unsloth)\n",
      "  Downloading protobuf-6.33.4-cp39-abi3-manylinux2014_aarch64.whl.metadata (593 bytes)\n",
      "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth)\n",
      "  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_aarch64.whl.metadata (10 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (1.7 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (10 kB)\n",
      "Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting accelerate>=0.34.1 (from unsloth)\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft!=0.11.0,>=0.18.0 (from unsloth)\n",
      "  Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth)\n",
      "  Downloading huggingface_hub-1.3.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Downloading diffusers-0.36.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 (from unsloth)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n",
      "  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filelock (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl.metadata (91 kB)\n",
      "Collecting requests>=2.32.2 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting httpx<1.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting xxhash (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pyyaml>=5.1 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (2.4 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading aiohttp-3.13.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (8.1 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_28_aarch64.whl.metadata (4.9 kB)\n",
      "Collecting shellingham (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting typing-extensions>=4.1.0 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth)\n",
      "  Downloading regex-2026.1.15-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.3 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (4.1 kB)\n",
      "Collecting torchao>=0.13.0 (from unsloth_zoo)\n",
      "  Downloading torchao-0.15.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting pillow (from unsloth_zoo)\n",
      "  Downloading pillow-12.1.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (8.8 kB)\n",
      "Collecting msgspec (from unsloth_zoo)\n",
      "  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (5.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (75 kB)\n",
      "Collecting setuptools (from torch>=2.4.0->unsloth)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.4.0->unsloth)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch>=2.4.0->unsloth)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.4.0->unsloth)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting importlib_metadata (from diffusers->unsloth)\n",
      "  Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting zipp>=3.20 (from importlib_metadata->diffusers->unsloth)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.4.0->unsloth)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (2.7 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading unsloth-2026.1.3-py3-none-any.whl (389 kB)\n",
      "Downloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_28_aarch64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n",
      "Downloading unsloth_zoo-2026.1.3-py3-none-any.whl (310 kB)\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading aiohttp-3.13.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.7.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (258 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (372 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_aarch64.whl (31.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.1/31.1 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_aarch64.whl (104.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.8.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (243 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.4.1-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (14.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading peft-0.18.1-py3-none-any.whl (556 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.0/557.0 kB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.4.1-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (225 kB)\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_aarch64.whl (45.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (775 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2026.1.15-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.7/798.7 kB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (148 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (491 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchao-0.15.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (159.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading diffusers-0.36.0-py3-none-any.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (24 kB)\n",
      "Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (218 kB)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl (11.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Downloading pillow-12.1.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.4-cp39-abi3-manylinux2014_aarch64.whl (324 kB)\n",
      "Downloading psutil-7.2.1-cp36-abi3-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (156 kB)\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_aarch64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-1.0.5-py3-none-any.whl (181 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (212 kB)\n",
      "Installing collected packages: torchao, pytz, mpmath, zipp, xxhash, wheel, urllib3, tzdata, typing-extensions, triton, tqdm, sympy, six, setuptools, sentencepiece, safetensors, regex, pyyaml, pyarrow, psutil, protobuf, propcache, pillow, packaging, numpy, networkx, multidict, msgspec, MarkupSafe, idna, hf-xet, hf_transfer, h11, fsspec, frozenlist, filelock, docstring-parser, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, typeguard, requests, python-dateutil, multiprocess, jinja2, importlib_metadata, httpcore, anyio, aiosignal, tyro, torch, pandas, huggingface_hub, httpx, aiohttp, torchvision, tokenizers, diffusers, cut_cross_entropy, bitsandbytes, accelerate, transformers, datasets, trl, peft, unsloth_zoo, unsloth\n",
      "\u001b[2K  Attempting uninstall: torchao\n",
      "\u001b[2K    Found existing installation: torchao 0.15.0\n",
      "\u001b[2K    Uninstalling torchao-0.15.0:\n",
      "\u001b[2K      Successfully uninstalled torchao-0.15.0\n",
      "\u001b[2K  Attempting uninstall: pytz━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/70\u001b[0m [torchao]\n",
      "\u001b[2K    Found existing installation: pytz 2025.2\u001b[0m \u001b[32m 0/70\u001b[0m [torchao]\n",
      "\u001b[2K    Uninstalling pytz-2025.2:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/70\u001b[0m [torchao]\n",
      "\u001b[2K      Successfully uninstalled pytz-2025.2━━\u001b[0m \u001b[32m 0/70\u001b[0m [torchao]\n",
      "\u001b[2K  Attempting uninstall: mpmath━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/70\u001b[0m [torchao]\n",
      "\u001b[2K    Found existing installation: mpmath 1.3.0[0m \u001b[32m 0/70\u001b[0m [torchao]\n",
      "\u001b[2K    Uninstalling mpmath-1.3.0:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/70\u001b[0m [torchao]\n",
      "\u001b[2K      Successfully uninstalled mpmath-1.3.0━\u001b[0m \u001b[32m 0/70\u001b[0m [torchao]\n",
      "\u001b[2K  Attempting uninstall: xxhash━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: xxhash 3.6.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling xxhash-3.6.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled xxhash-3.6.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: urllib3━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: urllib3 2.6.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling urllib3-2.6.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.6.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: tzdata━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: tzdata 2025.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling tzdata-2025.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled tzdata-2025.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/70\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/70\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.0━━━━━\u001b[0m \u001b[32m 7/70\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/70\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0━━━━━━━\u001b[0m \u001b[32m 7/70\u001b[0m [tzdata]\n",
      "\u001b[2K  Attempting uninstall: triton━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/70\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: triton 3.5.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/70\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling triton-3.5.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/70\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled triton-3.5.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/70\u001b[0m [tzdata]\n",
      "\u001b[2K  Attempting uninstall: tqdm[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/70\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/70\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/70\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/70\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/70\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/70\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/70\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/70\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: sixm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/70\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: six 1.17.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/70\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling six-1.17.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/70\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled six-1.17.0━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/70\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/70\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: setuptools 70.2.0━━━━━━━━━━━━\u001b[0m \u001b[32m12/70\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling setuptools-70.2.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/70\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled setuptools-70.2.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/70\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: sentencepiece━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/70\u001b[0m [setuptools]\n",
      "\u001b[2K    Found existing installation: sentencepiece 0.2.1━━━━━━━━━━\u001b[0m \u001b[32m13/70\u001b[0m [setuptools]\n",
      "\u001b[2K    Uninstalling sentencepiece-0.2.1:━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/70\u001b[0m [setuptools]\n",
      "\u001b[2K      Successfully uninstalled sentencepiece-0.2.1━━━━━━━━━━━━\u001b[0m \u001b[32m13/70\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: safetensors━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/70\u001b[0m [setuptools]\n",
      "\u001b[2K    Found existing installation: safetensors 0.7.0━━━━━━━━━━━━\u001b[0m \u001b[32m13/70\u001b[0m [setuptools]\n",
      "\u001b[2K    Uninstalling safetensors-0.7.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/70\u001b[0m [setuptools]\n",
      "\u001b[2K      Successfully uninstalled safetensors-0.7.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/70\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: regexm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/70\u001b[0m [setuptools]\n",
      "\u001b[2K    Found existing installation: regex 2026.1.15━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]]\n",
      "\u001b[2K    Uninstalling regex-2026.1.15:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]\n",
      "\u001b[2K      Successfully uninstalled regex-2026.1.15━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]\n",
      "\u001b[2K  Attempting uninstall: pyyaml0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]\n",
      "\u001b[2K    Found existing installation: PyYAML 6.0.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]\n",
      "\u001b[2K    Uninstalling PyYAML-6.0.3:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]\n",
      "\u001b[2K      Successfully uninstalled PyYAML-6.0.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]\n",
      "\u001b[2K  Attempting uninstall: pyarrowm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]\n",
      "\u001b[2K    Found existing installation: pyarrow 22.0.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]\n",
      "\u001b[2K    Uninstalling pyarrow-22.0.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]\n",
      "\u001b[2K      Successfully uninstalled pyarrow-22.0.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/70\u001b[0m [regex]\n",
      "\u001b[2K  Attempting uninstall: psutil0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: psutil 7.2.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling psutil-7.2.1:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled psutil-7.2.1━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: protobufm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: protobuf 6.33.4━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling protobuf-6.33.4:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.33.4━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: propcache━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: propcache 0.4.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling propcache-0.4.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled propcache-0.4.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: pillow90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: pillow 12.0.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling pillow-12.0.0:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled pillow-12.0.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/70\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: packagingm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/70\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/70\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling packaging-25.0:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/70\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/70\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: numpym╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/70\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.5━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/70\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling numpy-2.3.5:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/70\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.5━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/70\u001b[0m [packaging]\n",
      "\u001b[2K  Attempting uninstall: networkx[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/70\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: networkx 3.6.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/70\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling networkx-3.6.1:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/70\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled networkx-3.6.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/70\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: multidict[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/70\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: multidict 6.7.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/70\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling multidict-6.7.0:[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/70\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled multidict-6.7.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/70\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafe90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/70\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 2.1.5━━━━━━━━━━━━━\u001b[0m \u001b[32m25/70\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling MarkupSafe-2.1.5:90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/70\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-2.1.5━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/70\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: idna\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Found existing installation: idna 3.11━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Uninstalling idna-3.11:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K      Successfully uninstalled idna-3.11━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K  Attempting uninstall: hf-xet\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Found existing installation: hf-xet 1.2.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Uninstalling hf-xet-1.2.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K      Successfully uninstalled hf-xet-1.2.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K  Attempting uninstall: hf_transfer[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Found existing installation: hf_transfer 0.1.9━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Uninstalling hf_transfer-0.1.9:[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K      Successfully uninstalled hf_transfer-0.1.9━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K  Attempting uninstall: h110m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Found existing installation: h11 0.16.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Uninstalling h11-0.16.0:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K      Successfully uninstalled h11-0.16.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K  Attempting uninstall: fsspec\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.9.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Uninstalling fsspec-2025.9.0:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.9.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/70\u001b[0m [MarkupSafe]\n",
      "\u001b[2K  Attempting uninstall: frozenlistm╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: frozenlist 1.8.0━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling frozenlist-1.8.0:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled frozenlist-1.8.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: filelock\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: filelock 3.20.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling filelock-3.20.0:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.20.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: dill91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: dill 0.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling dill-0.4.0:91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: charset_normalizer━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.4.4━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.4.4:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.4━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: certifi╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: certifi 2026.1.4━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling certifi-2026.1.4:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled certifi-2026.1.4━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: attrs1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: attrs 25.4.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling attrs-25.4.0:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled attrs-25.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: aiohappyeyeballsm━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: aiohappyeyeballs 2.6.1━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling aiohappyeyeballs-2.6.1:m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled aiohappyeyeballs-2.6.1━━━━━━━━━\u001b[0m \u001b[32m33/70\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: yarl━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K    Found existing installation: yarl 1.22.00m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K    Uninstalling yarl-1.22.0:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K      Successfully uninstalled yarl-1.22.0[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K  Attempting uninstall: requests[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K    Found existing installation: requests 2.32.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K    Uninstalling requests-2.32.5:90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.5━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K  Attempting uninstall: python-dateutil0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K    Uninstalling python-dateutil-2.9.0.post0:m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K      Successfully uninstalled python-dateutil-2.9.0.post0━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K  Attempting uninstall: multiprocess╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.16━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.16:[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.16━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K  Attempting uninstall: jinja2m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.6m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.690m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/70\u001b[0m [aiohappyeyeballs]\n",
      "\u001b[2K  Attempting uninstall: httpcore━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]balls]\n",
      "\u001b[2K    Found existing installation: httpcore 1.0.90m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K    Uninstalling httpcore-1.0.9:0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K      Successfully uninstalled httpcore-1.0.9[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K  Attempting uninstall: anyio━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K    Found existing installation: anyio 4.12.1[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K    Uninstalling anyio-4.12.1:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K      Successfully uninstalled anyio-4.12.1m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K  Attempting uninstall: aiosignalm\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K    Found existing installation: aiosignal 1.4.0m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K    Uninstalling aiosignal-1.4.0:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K      Successfully uninstalled aiosignal-1.4.090m━━━━━━━━━━━━━\u001b[0m \u001b[32m47/70\u001b[0m [jinja2]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m52/70\u001b[0m [tyro]\n",
      "\u001b[2K    Found existing installation: torch 2.9.0+cu1300m━━━━━━━━━━\u001b[0m \u001b[32m52/70\u001b[0m [tyro]\n",
      "\u001b[2K    Uninstalling torch-2.9.0+cu130:0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m52/70\u001b[0m [tyro]\n",
      "\u001b[2K      Successfully uninstalled torch-2.9.0+cu130\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m53/70\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: pandas━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m53/70\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.3[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m53/70\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling pandas-2.3.3:━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m54/70\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.3╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m54/70\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: huggingface_hub[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m54/70\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: huggingface-hub 0.36.0━━━━━━━\u001b[0m \u001b[32m54/70\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling huggingface-hub-0.36.0:91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m54/70\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled huggingface-hub-0.36.0━━━━━━━━━\u001b[0m \u001b[32m54/70\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: httpx━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m55/70\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Found existing installation: httpx 0.28.1\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m55/70\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Uninstalling httpx-0.28.1:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m55/70\u001b[0m [huggingface_hub]\n",
      "\u001b[2K      Successfully uninstalled httpx-0.28.1m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m55/70\u001b[0m [huggingface_hub]\n",
      "\u001b[2K  Attempting uninstall: aiohttp━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m55/70\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Found existing installation: aiohttp 3.13.30m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m55/70\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Uninstalling aiohttp-3.13.3:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m55/70\u001b[0m [huggingface_hub]\n",
      "\u001b[2K      Successfully uninstalled aiohttp-3.13.3\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m55/70\u001b[0m [huggingface_hub]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m57/70\u001b[0m [aiohttp]hub]\n",
      "\u001b[2K    Found existing installation: torchvision 0.24.0[90m━━━━━━━\u001b[0m \u001b[32m57/70\u001b[0m [aiohttp]\n",
      "\u001b[2K    Uninstalling torchvision-0.24.0:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m57/70\u001b[0m [aiohttp]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.24.0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m57/70\u001b[0m [aiohttp]\n",
      "\u001b[2K  Attempting uninstall: tokenizers━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m58/70\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.21.4m\u001b[90m━━━━━━\u001b[0m \u001b[32m58/70\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling tokenizers-0.21.4:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m58/70\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.21.4[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m58/70\u001b[0m [torchvision]\n",
      "\u001b[2K  Attempting uninstall: cut_cross_entropy━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m60/70\u001b[0m [diffusers]\n",
      "\u001b[2K    Found existing installation: cut-cross-entropy 25.1.1━━━━━\u001b[0m \u001b[32m60/70\u001b[0m [diffusers]\n",
      "\u001b[2K    Uninstalling cut-cross-entropy-25.1.1:\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m60/70\u001b[0m [diffusers]\n",
      "\u001b[2K      Successfully uninstalled cut-cross-entropy-25.1.10m━━━━━\u001b[0m \u001b[32m60/70\u001b[0m [diffusers]\n",
      "\u001b[2K  Attempting uninstall: bitsandbytes━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m60/70\u001b[0m [diffusers]\n",
      "\u001b[2K    Found existing installation: bitsandbytes 0.49.1\u001b[90m━━━━━\u001b[0m \u001b[32m60/70\u001b[0m [diffusers]\n",
      "\u001b[2K    Uninstalling bitsandbytes-0.49.1:━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m60/70\u001b[0m [diffusers]\n",
      "\u001b[2K      Successfully uninstalled bitsandbytes-0.49.10m\u001b[90m━━━━━\u001b[0m \u001b[32m60/70\u001b[0m [diffusers]\n",
      "\u001b[2K  Attempting uninstall: accelerate━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m62/70\u001b[0m [bitsandbytes]\n",
      "\u001b[2K    Found existing installation: accelerate 1.12.0[0m\u001b[90m━━━━\u001b[0m \u001b[32m62/70\u001b[0m [bitsandbytes]\n",
      "\u001b[2K    Uninstalling accelerate-1.12.0:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m62/70\u001b[0m [bitsandbytes]\n",
      "\u001b[2K      Successfully uninstalled accelerate-1.12.0╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m62/70\u001b[0m [bitsandbytes]\n",
      "\u001b[2K  Attempting uninstall: transformers━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m63/70\u001b[0m [accelerate]\n",
      "\u001b[2K    Found existing installation: transformers 4.55.40m\u001b[90m━━━\u001b[0m \u001b[32m63/70\u001b[0m [accelerate]\n",
      "\u001b[2K    Uninstalling transformers-4.55.4:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m63/70\u001b[0m [accelerate]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.55.4\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m63/70\u001b[0m [accelerate]\n",
      "\u001b[2K  Attempting uninstall: datasets━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m64/70\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: datasets 4.3.01m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m64/70\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling datasets-4.3.0:━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m64/70\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled datasets-4.3.0\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m65/70\u001b[0m [datasets]\n",
      "\u001b[2K  Attempting uninstall: trl━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m65/70\u001b[0m [datasets]\n",
      "\u001b[2K    Found existing installation: trl 0.22.20m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m65/70\u001b[0m [datasets]\n",
      "\u001b[2K    Uninstalling trl-0.22.2:━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m65/70\u001b[0m [datasets]\n",
      "\u001b[2K      Successfully uninstalled trl-0.22.2\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m65/70\u001b[0m [datasets]\n",
      "\u001b[2K  Attempting uninstall: peft━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m66/70\u001b[0m [trl]]\n",
      "\u001b[2K    Found existing installation: peft 0.18.1m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m66/70\u001b[0m [trl]\n",
      "\u001b[2K    Uninstalling peft-0.18.1:━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m66/70\u001b[0m [trl]\n",
      "\u001b[2K      Successfully uninstalled peft-0.18.1[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m66/70\u001b[0m [trl]\n",
      "\u001b[2K  Attempting uninstall: unsloth_zoo━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m67/70\u001b[0m [peft]\n",
      "\u001b[2K    Found existing installation: unsloth_zoo 2026.1.2[0m\u001b[90m━\u001b[0m \u001b[32m67/70\u001b[0m [peft]\n",
      "\u001b[2K    Uninstalling unsloth_zoo-2026.1.2:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m67/70\u001b[0m [peft]\n",
      "\u001b[2K      Successfully uninstalled unsloth_zoo-2026.1.2╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m67/70\u001b[0m [peft]\n",
      "\u001b[2K  Attempting uninstall: unsloth━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m68/70\u001b[0m [unsloth_zoo]\n",
      "\u001b[2K    Found existing installation: unsloth 2026.1.21m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m68/70\u001b[0m [unsloth_zoo]\n",
      "\u001b[2K    Uninstalling unsloth-2026.1.2:━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m68/70\u001b[0m [unsloth_zoo]\n",
      "\u001b[2K      Successfully uninstalled unsloth-2026.1.2[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m68/70\u001b[0m [unsloth_zoo]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70/70\u001b[0m [unsloth]\u001b[0m [unsloth_zoo]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.9.0 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 anyio-4.12.1 attrs-25.4.0 bitsandbytes-0.49.1 certifi-2026.1.4 charset_normalizer-3.4.4 cut_cross_entropy-25.1.1 datasets-4.3.0 diffusers-0.36.0 dill-0.4.0 docstring-parser-0.17.0 filelock-3.20.3 frozenlist-1.8.0 fsspec-2025.9.0 h11-0.16.0 hf-xet-1.2.0 hf_transfer-0.1.9 httpcore-1.0.9 httpx-0.28.1 huggingface_hub-0.36.0 idna-3.11 importlib_metadata-8.7.1 jinja2-3.1.6 mpmath-1.3.0 msgspec-0.20.0 multidict-6.7.0 multiprocess-0.70.16 networkx-3.6.1 numpy-2.4.1 packaging-25.0 pandas-2.3.3 peft-0.18.1 pillow-12.1.0 propcache-0.4.1 protobuf-6.33.4 psutil-7.2.1 pyarrow-22.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2026.1.15 requests-2.32.5 safetensors-0.7.0 sentencepiece-0.2.1 setuptools-80.9.0 six-1.17.0 sympy-1.14.0 tokenizers-0.22.2 torch-2.9.1 torchao-0.15.0 torchvision-0.24.1 tqdm-4.67.1 transformers-4.57.3 triton-3.5.1 trl-0.24.0 typeguard-4.4.4 typing-extensions-4.15.0 tyro-1.0.5 tzdata-2025.3 unsloth-2026.1.3 unsloth_zoo-2026.1.3 urllib3-2.6.3 wheel-0.45.1 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torchao==0.14.0\n",
      "  Using cached torchao-0.14.0-py3-none-any.whl.metadata (19 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement fbgemm-gpu-genai==1.4.2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for fbgemm-gpu-genai==1.4.2\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 --index-url https://download.pytorch.org/whl/cu130\n",
    "\n",
    "import re\n",
    "\n",
    "import torch; v = re.match(r\"[0-9]{1,}\\.[0-9]{1,}\", str(torch.__version__)).group(0)\n",
    "xformers = \"xformers==\" + (\"0.0.33.post1\" if v==\"2.9\" else \"0.0.32.post2\" if v==\"2.8\" else \"0.0.29.post3\")\n",
    "%pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "%pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "%pip install --no-deps unsloth\n",
    "%pip install transformers==4.55.4\n",
    "%pip install --no-deps trl==0.22.2\n",
    "%pip install --upgrade --no-cache-dir --force-reinstall unsloth unsloth_zoo\n",
    "%pip install torchao==0.14.0 fbgemm-gpu-genai==1.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e2b608",
   "metadata": {},
   "source": [
    "## Load the Pre-trained Model\n",
    "\n",
    "Load the Llama-3.1-8B-Instruct model using Unsloth's `FastLanguageModel` for efficient inference and fine-tuning. The model is loaded in bfloat16 precision with a maximum sequence length of 2048 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b805316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2026.1.3: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA GB10. Num GPUs = 1. Max memory: 119.635 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu130. CUDA: 12.1. CUDA Toolkit: 13.0. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:20<00:00, 20.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "MODEL_ID=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "max_seq_length = 2048\n",
    "dtype = None  # Use None for QAT (will use float32)\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_ID,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed2f19a",
   "metadata": {},
   "source": [
    "## Inspect Model Architecture\n",
    "\n",
    "Display the model architecture to verify the model layers and structure before applying PEFT (Parameter-Efficient Fine-Tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c1e12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1da6b",
   "metadata": {},
   "source": [
    "## Apply LoRA and FP8 QAT\n",
    "\n",
    "Apply LoRA (Low-Rank Adaptation) adapters to the model with FP8 quantization-aware training scheme. This configures the model for efficient fine-tuning with FP8 fake quantization applied to specified target modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e19a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchao in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2026.1.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Applying QAT to mitigate quantization degradation\n"
     ]
    }
   ],
   "source": [
    "# %pip install torchao\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    qat_scheme = \"fp8-fp8\",\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90483d1",
   "metadata": {},
   "source": [
    "## Verify QAT Application\n",
    "\n",
    "Check if FP8 fake quantization has been successfully applied to the model by searching for `FakeQuantized` modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6843a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT is applied!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for module in model.modules():\n",
    "    if \"FakeQuantized\" in module.__class__.__name__:\n",
    "        print(\"QAT is applied!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d6cd02",
   "metadata": {},
   "source": [
    "## Configure Chat Template\n",
    "\n",
    "Set up the Llama 3 chat template for the tokenizer to properly format conversational inputs during training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7aae5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8a96a9",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Add your training or inference code below. The model is now configured with LoRA adapters and FP8 quantization-aware training (QAT) scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d622c24",
   "metadata": {},
   "source": [
    "## Load Training Dataset\n",
    "\n",
    "Load the FineTome-100k dataset which contains high-quality instruction-following data for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2c8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5f80b",
   "metadata": {},
   "source": [
    "## Standardize Dataset Format\n",
    "\n",
    "Convert the dataset to a standardized format compatible with Unsloth's chat template processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abe8ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import standardize_data_formats\n",
    "dataset = standardize_data_formats(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1b3094",
   "metadata": {},
   "source": [
    "## Inspect Dataset Sample\n",
    "\n",
    "Display a sample entry from the dataset to verify the data structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a491b2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'content': 'What is the modulus operator in programming and how can I use it to calculate the modulus of two given numbers?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'In programming, the modulus operator is represented by the \\'%\\' symbol. It calculates the remainder when one number is divided by another. To calculate the modulus of two given numbers, you can use the modulus operator in the following way:\\n\\n```python\\n# Calculate the modulus\\nModulus = a % b\\n\\nprint(\"Modulus of the given numbers is: \", Modulus)\\n```\\n\\nIn this code snippet, the variables \\'a\\' and \\'b\\' represent the two given numbers for which you want to calculate the modulus. By using the modulus operator \\'%\\', we calculate the remainder when \\'a\\' is divided by \\'b\\'. The result is then stored in the variable \\'Modulus\\'. Finally, the modulus value is printed using the \\'print\\' statement.\\n\\nFor example, if \\'a\\' is 10 and \\'b\\' is 4, the modulus calculation would be 10 % 4, which equals 2. Therefore, the output of the above code would be:\\n\\n```\\nModulus of the given numbers is: 2\\n```\\n\\nThis means that the modulus of 10 and 4 is 2.',\n",
       "   'role': 'assistant'}],\n",
       " 'source': 'infini-instruct-top-500k',\n",
       " 'score': 4.774171352386475}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6432bc5",
   "metadata": {},
   "source": [
    "## Format Dataset for Training\n",
    "\n",
    "Apply the chat template to each conversation in the dataset, converting them into properly formatted text strings for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583df354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "   convos = examples[\"conversations\"]\n",
    "   texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
    "   return { \"text\" : texts, }\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f270a24",
   "metadata": {},
   "source": [
    "## Verify Formatted Text\n",
    "\n",
    "Display a formatted text sample to verify the chat template has been correctly applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc41e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is the modulus operator in programming and how can I use it to calculate the modulus of two given numbers?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nIn programming, the modulus operator is represented by the \\'%\\' symbol. It calculates the remainder when one number is divided by another. To calculate the modulus of two given numbers, you can use the modulus operator in the following way:\\n\\n```python\\n# Calculate the modulus\\nModulus = a % b\\n\\nprint(\"Modulus of the given numbers is: \", Modulus)\\n```\\n\\nIn this code snippet, the variables \\'a\\' and \\'b\\' represent the two given numbers for which you want to calculate the modulus. By using the modulus operator \\'%\\', we calculate the remainder when \\'a\\' is divided by \\'b\\'. The result is then stored in the variable \\'Modulus\\'. Finally, the modulus value is printed using the \\'print\\' statement.\\n\\nFor example, if \\'a\\' is 10 and \\'b\\' is 4, the modulus calculation would be 10 % 4, which equals 2. Therefore, the output of the above code would be:\\n\\n```\\nModulus of the given numbers is: 2\\n```\\n\\nThis means that the modulus of 10 and 4 is 2.<|eot_id|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c2ac0f",
   "metadata": {},
   "source": [
    "## Configure Training\n",
    "\n",
    "Set up the Supervised Fine Tuning (SFT) Trainer with training arguments including batch size, learning rate, optimizer, and training steps for fine-tuning the model with FP8 QAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825d6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[trl.trainer.sft_trainer|WARNING]You are using a per_device_train_batch_size of 1 with padding-free training. Using a batch size of 1 anihilate the benefits of padding-free training. Please consider increasing the batch size to at least 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Padding-free auto-enabled, enabling faster training.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    eval_dataset = None, # Can set up evaluation!\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 30,\n",
    "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.001,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085f0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
