{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb086515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"12.1\"\n",
    "os.environ[\"TRITON_PTXAS_PATH\"] = \"/usr/local/cuda/bin/ptxas\"\n",
    "os.environ[\"PATH\"] = \"/usr/local/cuda/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59fb715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu130\n",
      "Requirement already satisfied: torch==2.9.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (2.9.0+cu130)\n",
      "Requirement already satisfied: torchvision==0.24.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.24.0)\n",
      "Requirement already satisfied: torchaudio==2.9.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.13.0.50 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (9.13.0.50)\n",
      "Requirement already satisfied: nvidia-cublas==13.0.0.19 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.0.19)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.15 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (12.0.0.15)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.3.29 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (12.0.3.29)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.2.49 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (12.6.2.49)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.27.7 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (2.27.7)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.3.24 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.3.24)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.39)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.39)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.0.42 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (1.15.0.42)\n",
      "Requirement already satisfied: triton==3.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.5.0)\n",
      "Requirement already satisfied: numpy in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torchvision==0.24.0) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torchvision==0.24.0) (12.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.9.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from jinja2->torch==2.9.0) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: unsloth in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (2026.1.3)\n",
      "Requirement already satisfied: unsloth_zoo in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (2026.1.3)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: torch>=2.4.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (2.9.0+cu130)\n",
      "Requirement already satisfied: torchvision in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (0.24.0)\n",
      "Requirement already satisfied: numpy in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (2.4.1)\n",
      "Requirement already satisfied: tqdm in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (7.2.1)\n",
      "Requirement already satisfied: tyro in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (1.0.5)\n",
      "Requirement already satisfied: protobuf in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (6.33.4)\n",
      "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (0.49.1)\n",
      "Requirement already satisfied: triton>=3.0.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (3.5.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (0.2.1)\n",
      "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (4.3.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (1.12.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.18.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (0.18.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (4.55.4)\n",
      "Requirement already satisfied: trl!=0.19.0,<=0.24.0,>=0.18.2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth) (0.22.2)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\n",
      "Requirement already satisfied: pandas in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.3)\n",
      "Requirement already satisfied: anyio in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.12.1)\n",
      "Requirement already satisfied: certifi in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\n",
      "Requirement already satisfied: idna in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.7.0)\n",
      "Requirement already satisfied: torchao>=0.13.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.15.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth_zoo) (25.1.1)\n",
      "Requirement already satisfied: pillow in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth_zoo) (12.1.0)\n",
      "Requirement already satisfied: msgspec in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from unsloth_zoo) (0.20.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\n",
      "Requirement already satisfied: setuptools in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.48 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.13.0.50 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (9.13.0.50)\n",
      "Requirement already satisfied: nvidia-cublas==13.0.0.19 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (13.0.0.19)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.15 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.0.0.15)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.3.29 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.0.3.29)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.2.49 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.6.2.49)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.27.7 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (2.27.7)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.3.24 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.3.24)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (13.0.39)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.39 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (13.0.39)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.0.42 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (1.15.0.42)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: importlib_metadata in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from diffusers->unsloth) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from tyro->unsloth) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from tyro->unsloth) (4.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torchao==0.14.0\n",
      "  Using cached torchao-0.14.0-py3-none-any.whl.metadata (19 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement fbgemm-gpu-genai==1.4.2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for fbgemm-gpu-genai==1.4.2\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers==4.55.4 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (4.55.4)\n",
      "Requirement already satisfied: filelock in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (2026.1.15)\n",
      "Requirement already satisfied: requests in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from transformers==4.55.4) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers==4.55.4) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers==4.55.4) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers==4.55.4) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (from requests->transformers==4.55.4) (2026.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: trl==0.22.2 in /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages (0.22.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Using pip 25.3 from /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/pip (python 3.12)\n",
      "Collecting xformers\n",
      "  Cloning https://github.com/facebookresearch/xformers.git (to revision main) to /tmp/pip-install-d7gb2oae/xformers_0c3a62b9ee8441309752b82eb8d1fdcb\n",
      "  Running command git version\n",
      "  git version 2.43.0\n",
      "  Running command git clone --filter=blob:none https://github.com/facebookresearch/xformers.git /tmp/pip-install-d7gb2oae/xformers_0c3a62b9ee8441309752b82eb8d1fdcb\n",
      "  Cloning into '/tmp/pip-install-d7gb2oae/xformers_0c3a62b9ee8441309752b82eb8d1fdcb'...\n",
      "  Running command git show-ref main\n",
      "  5f95c7af062663cb53087a61d89e2c29273ce6c2 refs/heads/main\n",
      "  5f95c7af062663cb53087a61d89e2c29273ce6c2 refs/remotes/origin/main\n",
      "  Running command git symbolic-ref -q HEAD\n",
      "  refs/heads/main\n",
      "  Resolved https://github.com/facebookresearch/xformers.git to commit 5f95c7af062663cb53087a61d89e2c29273ce6c2\n",
      "  Running command git submodule update --init --recursive\n",
      "  Submodule 'third_party/composable_kernel_tiled' (https://github.com/ROCm/composable_kernel.git) registered for path 'third_party/composable_kernel_tiled'\n",
      "  Submodule 'third_party/cutlass' (https://github.com/NVIDIA/cutlass.git) registered for path 'third_party/cutlass'\n",
      "  Submodule 'third_party/flash-attention' (https://github.com/Dao-AILab/flash-attention.git) registered for path 'third_party/flash-attention'\n",
      "  Cloning into '/tmp/pip-install-d7gb2oae/xformers_0c3a62b9ee8441309752b82eb8d1fdcb/third_party/composable_kernel_tiled'...\n",
      "  Cloning into '/tmp/pip-install-d7gb2oae/xformers_0c3a62b9ee8441309752b82eb8d1fdcb/third_party/cutlass'...\n",
      "  Cloning into '/tmp/pip-install-d7gb2oae/xformers_0c3a62b9ee8441309752b82eb8d1fdcb/third_party/flash-attention'...\n",
      "  Submodule path 'third_party/composable_kernel_tiled': checked out '50fad035248b154cdfa4505cf5de7465ce146149'\n",
      "  Submodule path 'third_party/cutlass': checked out '8afb19d9047afc26816a046059afe66763e68aa5'\n",
      "  Submodule path 'third_party/flash-attention': checked out 'de1584b5328321189a4d7832fe29bbd6813bf6ed'\n",
      "  Submodule 'csrc/composable_kernel' (https://github.com/ROCm/composable_kernel.git) registered for path 'third_party/flash-attention/csrc/composable_kernel'\n",
      "  Submodule 'csrc/cutlass' (https://github.com/NVIDIA/cutlass.git) registered for path 'third_party/flash-attention/csrc/cutlass'\n",
      "  Cloning into '/tmp/pip-install-d7gb2oae/xformers_0c3a62b9ee8441309752b82eb8d1fdcb/third_party/flash-attention/csrc/composable_kernel'...\n",
      "  Cloning into '/tmp/pip-install-d7gb2oae/xformers_0c3a62b9ee8441309752b82eb8d1fdcb/third_party/flash-attention/csrc/cutlass'...\n",
      "  Submodule path 'third_party/flash-attention/csrc/composable_kernel': checked out 'e8709c24f403173ad21a2da907d1347957e324fb'\n",
      "  Submodule path 'third_party/flash-attention/csrc/cutlass': checked out 'b1d6e2c9b334dfa811e4183dfbd02419249e4b52'\n",
      "  Running command git rev-parse HEAD\n",
      "  5f95c7af062663cb53087a61d89e2c29273ce6c2\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l  Running command Preparing metadata (pyproject.toml)\n",
      "  Traceback (most recent call last):\n",
      "    File \"/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "      main()\n",
      "    File \"/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "      json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 175, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/setuptools/build_meta.py\", line 374, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 626, in <module>\n",
      "    File \"<string>\", line 270, in get_extensions\n",
      "  RuntimeError: This version of xFormers requires PyTorch 2.10+. You have PyTorch 2.9.0+cu130. For previous versions of PyTorch, check out v0.0.33 of xFormers or earlier.\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m No available output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[1;35mfull command\u001b[0m: \u001b[34m/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/bin/python /root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py prepare_metadata_for_build_wheel /tmp/tmpak7fknwv\u001b[0m\n",
      "  \u001b[1;35mcwd\u001b[0m: /tmp/pip-install-d7gb2oae/xformers_0c3a62b9ee8441309752b82eb8d1fdcb\n",
      "\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31mâ•°â”€>\u001b[0m xformers\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 --index-url https://download.pytorch.org/whl/cu130\n",
    "%pip install --upgrade unsloth unsloth_zoo\n",
    "%pip install torchao==0.14.0 fbgemm-gpu-genai==1.4.2\n",
    "%pip install transformers==4.55.4\n",
    "%pip install --no-deps trl==0.22.2\n",
    "%pip install -v -U --no-build-isolation -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b805316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/src/github.com/elizabetht/language-modeling-from-scratch/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2026.1.3: Fast Llama patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    NVIDIA GB10. Num GPUs = 1. Max memory: 119.635 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu130. CUDA: 12.1. CUDA Toolkit: 13.0. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5046bac0d5ac474e90ce39e5693565d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "MODEL_ID=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "max_seq_length = 2048\n",
    "dtype = torch.bfloat16\n",
    "lora_rank = 32\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_ID,\n",
    "    dtype=dtype,\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=False,\n",
    "    fast_inference=False,\n",
    "    max_lora_rank = lora_rank\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c1e12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49b128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2026.1.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Applying QAT to mitigate quantization degradation\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules= [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    lora_alpha = lora_rank * 2,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3047,\n",
    "    qat_scheme = \"fp8-int4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6843a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT is applied!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for module in model.modules():\n",
    "    if \"FakeQuantized\" in module.__class__.__name__:\n",
    "        print(\"QAT is applied!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbf732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template=\"llama3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61845fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e107a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import standardize_data_formats\n",
    "dataset = standardize_data_formats(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a7c98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'content': 'What is the modulus operator in programming and how can I use it to calculate the modulus of two given numbers?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'In programming, the modulus operator is represented by the \\'%\\' symbol. It calculates the remainder when one number is divided by another. To calculate the modulus of two given numbers, you can use the modulus operator in the following way:\\n\\n```python\\n# Calculate the modulus\\nModulus = a % b\\n\\nprint(\"Modulus of the given numbers is: \", Modulus)\\n```\\n\\nIn this code snippet, the variables \\'a\\' and \\'b\\' represent the two given numbers for which you want to calculate the modulus. By using the modulus operator \\'%\\', we calculate the remainder when \\'a\\' is divided by \\'b\\'. The result is then stored in the variable \\'Modulus\\'. Finally, the modulus value is printed using the \\'print\\' statement.\\n\\nFor example, if \\'a\\' is 10 and \\'b\\' is 4, the modulus calculation would be 10 % 4, which equals 2. Therefore, the output of the above code would be:\\n\\n```\\nModulus of the given numbers is: 2\\n```\\n\\nThis means that the modulus of 10 and 4 is 2.',\n",
       "   'role': 'assistant'}],\n",
       " 'source': 'infini-instruct-top-500k',\n",
       " 'score': 4.774171352386475}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1abe32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt=False) for convo in convos]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441c23cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is the modulus operator in programming and how can I use it to calculate the modulus of two given numbers?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nIn programming, the modulus operator is represented by the \\'%\\' symbol. It calculates the remainder when one number is divided by another. To calculate the modulus of two given numbers, you can use the modulus operator in the following way:\\n\\n```python\\n# Calculate the modulus\\nModulus = a % b\\n\\nprint(\"Modulus of the given numbers is: \", Modulus)\\n```\\n\\nIn this code snippet, the variables \\'a\\' and \\'b\\' represent the two given numbers for which you want to calculate the modulus. By using the modulus operator \\'%\\', we calculate the remainder when \\'a\\' is divided by \\'b\\'. The result is then stored in the variable \\'Modulus\\'. Finally, the modulus value is printed using the \\'print\\' statement.\\n\\nFor example, if \\'a\\' is 10 and \\'b\\' is 4, the modulus calculation would be 10 % 4, which equals 2. Therefore, the output of the above code would be:\\n\\n```\\nModulus of the given numbers is: 2\\n```\\n\\nThis means that the modulus of 10 and 4 is 2.<|eot_id|>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "641f07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "825d6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[trl.trainer.sft_trainer|WARNING]You are using a per_device_train_batch_size of 1 with padding-free training. Using a batch size of 1 anihilate the benefits of padding-free training. Please consider increasing the batch size to at least 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Padding-free auto-enabled, enabling faster training.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    # dataset_text_field = \"text\",\n",
    "    # max_seq_length = max_seq_length,\n",
    "    # packing = False,\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 30,\n",
    "        learning_rate = 2e-5,\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.001,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchao.quantization import quantize_\n",
    "from torchao.quantization.qat import QATConfig\n",
    "\n",
    "quantize_(model, QATConfig(step = \"convert\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b3ec8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchao.quantization import quantize_\n",
    "from torchao.quantization.qat import QATConfig\n",
    "\n",
    "quantize_(model, QATConfig(step = \"convert\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52bb88e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sequence you're referring to is the Fibonacci sequence, in which each number is the sum of the two preceding numbers. The next numbers in the sequence would be:\n",
      "\n",
      "13, 21, 34, 55, 89, 144,...\n",
      "\n",
      "So, the continued sequence is: 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\" : \"user\", \"content\" : \"Continue the sequence: 1, 1, 2, 3, 5, 8,\"}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 1000, # Increase for longer outputs!\n",
    "    temperature = 0.7, top_p = 0.8, top_k = 20, # For non thinking\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bd092bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/chat_template.jinja',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"lora_model\")  # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6e75806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Copying 4 files from cache to `model`: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully copied all 4 files from cache to `model`\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 166111.05it/s]\n",
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:42<00:00, 25.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/root/src/github.com/elizabetht/language-modeling-from-scratch/quantization/unsloth/model`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357c0a25197645c98f008df34dbf065f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save_pretrained_torchao(\n",
    "    \"model-torchao\",\n",
    "    tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8aaabdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Repository created: tokenlabsdotrun/Llama-3.1-8B-Unsloth-FP8-QAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "[huggingface_hub.hf_api|WARNING]No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model card uploaded\n",
      "Uploading from: /root/src/github.com/elizabetht/language-modeling-from-scratch/quantization/unsloth/model-torchao\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a5da7c61194f76b64139962b28acaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1795441d4641a79c130a176adc2183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Uploaded to https://huggingface.co/tokenlabsdotrun/Llama-3.1-8B-Unsloth-FP8-QAT\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login, ModelCard, ModelCardData, create_repo, upload_folder\n",
    "\n",
    "load_dotenv()\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "# Generate model card\n",
    "repo_id = \"tokenlabsdotrun/Llama-3.1-8B-Unsloth-FP8-QAT\"\n",
    "hf_write_token = os.getenv(\"HF_WRITE_TOKEN\")\n",
    "\n",
    "card_data = ModelCardData(\n",
    "    language=\"en\",\n",
    "    license=\"llama3.1\",\n",
    "    base_model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    tags=[\"fp8\", \"qat\", \"quantization-aware-training\", \"unsloth\", \"llama\", \"lora\"],\n",
    "    pipeline_tag=\"text-generation\",\n",
    ")\n",
    "\n",
    "card_content = f\"\"\"\n",
    "---\n",
    "{card_data.to_yaml()}\n",
    "---\n",
    "\n",
    "# Llama-3.1-8B FP8 QAT Fine-tuned with Unsloth\n",
    "\n",
    "This model was fine-tuned using **FP8 Quantization-Aware Training (QAT)** with [Unsloth](https://github.com/unslothai/unsloth).\n",
    "\n",
    "## Model Details\n",
    "\n",
    "- **Base Model**: meta-llama/Llama-3.1-8B-Instruct\n",
    "- **Fine-tuning Method**: LoRA + FP8 QAT\n",
    "- **QAT Scheme**: fp8-int4\n",
    "- **LoRA Rank**: 32\n",
    "- **Training Dataset**: mlabonne/FineTome-100k\n",
    "\n",
    "## What is FP8 QAT?\n",
    "\n",
    "FP8 Quantization-Aware Training trains the model to be robust to FP8 precision loss by simulating quantization during training. This results in:\n",
    "- Minimal accuracy degradation when deployed in FP8\n",
    "- Faster inference with FP8 hardware support\n",
    "- Reduced memory footprint\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"{repo_id}\",\n",
    "    dtype=torch.bfloat16,\n",
    "    max_seq_length=2048,\n",
    ")\n",
    "```\n",
    "\n",
    "## Training Configuration\n",
    "\n",
    "- Learning rate: 2e-5\n",
    "- Batch size: 1 (with gradient accumulation of 4)\n",
    "- Optimizer: AdamW 8-bit\n",
    "- Training steps: 30\n",
    "\n",
    "## License\n",
    "\n",
    "This model is released under the Llama 3.1 Community License.\n",
    "\"\"\"\n",
    "\n",
    "card = ModelCard(card_content)\n",
    "\n",
    "# Upload to HuggingFace Hub\n",
    "try:\n",
    "    # Create the repo (set private=True if you want it private)\n",
    "    create_repo(repo_id, exist_ok=True, private=False, token=hf_write_token)\n",
    "    print(f\"âœ“ Repository created: {repo_id}\")\n",
    "    \n",
    "    # Push model card\n",
    "    card.push_to_hub(repo_id, token=hf_write_token)\n",
    "    print(f\"âœ“ Model card uploaded\")\n",
    "    \n",
    "    # Upload all files from local save\n",
    "    model_path = os.path.join(os.getcwd(), \"model-torchao\")\n",
    "    print(f\"Uploading from: {model_path}\")\n",
    "    upload_folder(\n",
    "        folder_path=model_path,\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"model\",\n",
    "        commit_message=\"Upload Llama-3.1-8B fine-tuned with Unsloth FP8 QAT\",\n",
    "        token=hf_write_token\n",
    "    )\n",
    "    print(f\"âœ“ Uploaded to https://huggingface.co/{repo_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a745aed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
