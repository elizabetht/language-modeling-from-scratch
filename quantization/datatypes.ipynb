{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190e487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu130\n",
      "Collecting torch==2.9.0\n",
      "  Downloading https://download.pytorch.org/whl/cu130/torch-2.9.0%2Bcu130-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (2025.12.0)\n",
      "Collecting nvidia-cuda-nvrtc==13.0.48 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-cuda-nvrtc/nvidia_cuda_nvrtc-13.0.48-py3-none-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (43.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cuda-runtime==13.0.48 in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (13.0.48)\n",
      "Collecting nvidia-cuda-cupti==13.0.48 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-cuda-cupti/nvidia_cuda_cupti-13.0.48-py3-none-manylinux_2_25_aarch64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu13==9.13.0.50 in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (9.13.0.50)\n",
      "Collecting nvidia-cublas==13.0.0.19 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-cublas/nvidia_cublas-13.0.0.19-py3-none-manylinux_2_27_aarch64.whl (539.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m539.0/539.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft==12.0.0.15 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-cufft/nvidia_cufft-12.0.0.15-py3-none-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (214.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.1/214.1 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-curand==10.4.0.35 in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (10.4.0.35)\n",
      "Collecting nvidia-cusolver==12.0.3.29 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-cusolver/nvidia_cusolver-12.0.3.29-py3-none-manylinux_2_27_aarch64.whl (193.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse==12.6.2.49 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-cusparse/nvidia_cusparse-12.6.2.49-py3-none-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (155.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.9/155.9 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in ./.venv/lib/python3.12/site-packages (from torch==2.9.0) (0.8.0)\n",
      "Collecting nvidia-nccl-cu13==2.27.7 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-nccl-cu13/nvidia_nccl_cu13-2.27.7-py3-none-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (194.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.0/194.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvshmem-cu13==3.3.24 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-nvshmem-cu13/nvidia_nvshmem_cu13-3.3.24-py3-none-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (60.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx==13.0.39 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-nvtx/nvidia_nvtx-13.0.39-py3-none-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.0/148.0 kB\u001b[0m \u001b[31m295.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink==13.0.39 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-nvjitlink/nvidia_nvjitlink-13.0.39-py3-none-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (38.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufile==1.15.0.42 (from torch==2.9.0)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-cufile/nvidia_cufile-1.15.0.42-py3-none-manylinux_2_27_aarch64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.5.0 (from torch==2.9.0)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.5.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.9.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch==2.9.0) (3.0.3)\n",
      "Downloading https://download.pytorch.org/whl/cu130/torch-2.9.0%2Bcu130-cp312-cp312-manylinux_2_28_aarch64.whl (512.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.5.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (159.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx, nvidia-nvshmem-cu13, nvidia-nvjitlink, nvidia-nccl-cu13, nvidia-cufile, nvidia-cuda-nvrtc, nvidia-cuda-cupti, nvidia-cublas, nvidia-cusparse, nvidia-cufft, nvidia-cusolver, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.6.0+git8fedd49b\n",
      "    Uninstalling triton-3.6.0+git8fedd49b:\n",
      "      Successfully uninstalled triton-3.6.0+git8fedd49b\n",
      "  Attempting uninstall: nvidia-nvtx\n",
      "    Found existing installation: nvidia-nvtx 13.0.85\n",
      "    Uninstalling nvidia-nvtx-13.0.85:\n",
      "      Successfully uninstalled nvidia-nvtx-13.0.85\n",
      "  Attempting uninstall: nvidia-nvshmem-cu13\n",
      "    Found existing installation: nvidia-nvshmem-cu13 3.4.5\n",
      "    Uninstalling nvidia-nvshmem-cu13-3.4.5:\n",
      "      Successfully uninstalled nvidia-nvshmem-cu13-3.4.5\n",
      "  Attempting uninstall: nvidia-nvjitlink\n",
      "    Found existing installation: nvidia-nvjitlink 13.0.88\n",
      "    Uninstalling nvidia-nvjitlink-13.0.88:\n",
      "      Successfully uninstalled nvidia-nvjitlink-13.0.88\n",
      "  Attempting uninstall: nvidia-nccl-cu13\n",
      "    Found existing installation: nvidia-nccl-cu13 2.28.9\n",
      "    Uninstalling nvidia-nccl-cu13-2.28.9:\n",
      "      Successfully uninstalled nvidia-nccl-cu13-2.28.9\n",
      "  Attempting uninstall: nvidia-cufile\n",
      "    Found existing installation: nvidia-cufile 1.15.1.6\n",
      "    Uninstalling nvidia-cufile-1.15.1.6:\n",
      "      Successfully uninstalled nvidia-cufile-1.15.1.6\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc\n",
      "    Found existing installation: nvidia-cuda-nvrtc 13.0.88\n",
      "    Uninstalling nvidia-cuda-nvrtc-13.0.88:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-13.0.88\n",
      "  Attempting uninstall: nvidia-cuda-cupti\n",
      "    Found existing installation: nvidia-cuda-cupti 13.0.85\n",
      "    Uninstalling nvidia-cuda-cupti-13.0.85:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-13.0.85\n",
      "  Attempting uninstall: nvidia-cublas\n",
      "    Found existing installation: nvidia-cublas 13.1.0.3\n",
      "    Uninstalling nvidia-cublas-13.1.0.3:\n",
      "      Successfully uninstalled nvidia-cublas-13.1.0.3\n",
      "  Attempting uninstall: nvidia-cusparse\n",
      "    Found existing installation: nvidia-cusparse 12.6.3.3\n",
      "    Uninstalling nvidia-cusparse-12.6.3.3:\n",
      "      Successfully uninstalled nvidia-cusparse-12.6.3.3\n",
      "  Attempting uninstall: nvidia-cufft\n",
      "    Found existing installation: nvidia-cufft 12.0.0.61\n",
      "    Uninstalling nvidia-cufft-12.0.0.61:\n",
      "      Successfully uninstalled nvidia-cufft-12.0.0.61\n",
      "  Attempting uninstall: nvidia-cusolver\n",
      "    Found existing installation: nvidia-cusolver 12.0.4.66\n",
      "    Uninstalling nvidia-cusolver-12.0.4.66:\n",
      "      Successfully uninstalled nvidia-cusolver-12.0.4.66\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.11.0.dev20251214+cu130\n",
      "    Uninstalling torch-2.11.0.dev20251214+cu130:\n",
      "      Successfully uninstalled torch-2.11.0.dev20251214+cu130\n",
      "Successfully installed nvidia-cublas-13.0.0.19 nvidia-cuda-cupti-13.0.48 nvidia-cuda-nvrtc-13.0.48 nvidia-cufft-12.0.0.15 nvidia-cufile-1.15.0.42 nvidia-cusolver-12.0.3.29 nvidia-cusparse-12.6.2.49 nvidia-nccl-cu13-2.27.7 nvidia-nvjitlink-13.0.39 nvidia-nvshmem-cu13-3.3.24 nvidia-nvtx-13.0.39 torch-2.9.0+cu130 triton-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.9.0 --index-url https://download.pytorch.org/whl/cu130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fa3396c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 17 15:32:44 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GB10                    On  |   0000000F:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P0             10W /  N/A  | Not Supported          |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A         1659476      C   VLLM::EngineCore                      96808MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f907bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-128, max=127, dtype=int8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.iinfo(torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b02fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=0, max=255, dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.iinfo(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca5c3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-9.22337e+18, max=9.22337e+18, dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.iinfo(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66fe6306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-2.14748e+09, max=2.14748e+09, dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.iinfo(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f6b013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-32768, max=32767, dtype=int16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.iinfo(torch.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be17670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.01, min=-3.38953e+38, max=3.38953e+38, eps=0.0078125, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=bfloat16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.finfo(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4018559f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.finfo(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47484a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=1, min=-448, max=448, eps=0.125, smallest_normal=0.015625, tiny=0.015625, dtype=float8_e4m3fn)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.finfo(torch.float8_e4m3fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5435e761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=1, min=-240, max=240, eps=0.125, smallest_normal=0.0078125, tiny=0.0078125, dtype=float8_e4m3fnuz)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.finfo(torch.float8_e4m3fnuz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bf81a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float4_e2m1fn not available as standalone dtype\n",
      "float4_e2m1fn_x2 packs two 4-bit floats (E2M1 format):\n",
      "- 1 sign bit, 2 exponent bits, 1 mantissa bit per value\n",
      "- Range: approximately ±6.0\n",
      "- Precision: very limited, used for extreme compression\n"
     ]
    }
   ],
   "source": [
    "# torch.float4_e2m1fn_x2 is a packed format (2 float4 values in 1 byte)\n",
    "# You cannot use finfo() on packed formats\n",
    "# Instead, use the underlying float4 format:\n",
    "try:\n",
    "    torch.finfo(torch.float4_e2m1fn)\n",
    "except AttributeError:\n",
    "    print(\"float4_e2m1fn not available as standalone dtype\")\n",
    "    print(\"float4_e2m1fn_x2 packs two 4-bit floats (E2M1 format):\")\n",
    "    print(\"- 1 sign bit, 2 exponent bits, 1 mantissa bit per value\")\n",
    "    print(\"- Range: approximately ±6.0\")\n",
    "    print(\"- Precision: very limited, used for extreme compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5488667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78932e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.333333333333333314829616256247390992939472198486328125000000'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(value, \".60f\")  # 6 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf5d4331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333 0.333333333333333314829616256247390992939472198486328125000000\n"
     ]
    }
   ],
   "source": [
    "tensor_fp64 = torch.tensor(value, dtype=torch.float64)  # 15-17 decimal places\n",
    "print(tensor_fp64.item(), format(tensor_fp64.item(), \".60f\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7f095f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_fp32 = torch.tensor(value, dtype=torch.float32)  # 6-9 decimal places\n",
    "tensor_fp16 = torch.tensor(value, dtype=torch.float16)  # 3-4 decimal places\n",
    "tensor_bf16 = torch.tensor(value, dtype=torch.bfloat16)  # 3-4 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d977507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333333343267440795898437500000000000000000000000000000000000\n",
      "0.333251953125000000000000000000000000000000000000000000000000\n",
      "0.333984375000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "print(format(tensor_fp32.item(), \".60f\"))\n",
    "print(format(tensor_fp16.item(), \".60f\"))\n",
    "print(format(tensor_bf16.item(), \".60f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1816aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6749, 0.0091, 0.1369, 0.8139, 0.8935])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_fp32 = torch.rand(1000, dtype=torch.float32)\n",
    "tensor_fp32[:5]  # Show first 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3eadfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6758, 0.0091, 0.1367, 0.8125, 0.8945], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_fp32_to_bf16 = tensor_fp32.to(torch.bfloat16)\n",
    "tensor_fp32_to_bf16[:5]  # Show first 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8004cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353.1943664550781"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tensor = torch.dot(tensor_fp32, tensor_fp32)\n",
    "m_tensor.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f64d91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tensor_bf16 = torch.dot(tensor_fp32_to_bf16, tensor_fp32_to_bf16)\n",
    "m_tensor_bf16.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20bdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
